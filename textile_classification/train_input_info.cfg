[HyperParameters]
number_of_epochs = 1
batch_size = 32
lr_start = 1e-4
# Two following variables decay the learning rate by gamma every step_size epochs.
lr_gamma_decay = 0.5
lr_stepsize_decay = 50
# selected_model must be efficientnet, resnext or densenet
selected_model = densenet
[ExperimentIDs]
# mlflow will gerenate logs under this experiment_name
# you also can assign it none
experiment_name = first_training_densenet
[Checkpoint]
# checkpoint_file is the path of previous checkpoint to continue training from it.
# it is a .pt file already saved by the pytorch.save() function. 
# if you can also assign it none.
checkpoint_file = none