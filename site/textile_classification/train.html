<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>Train - Home</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
        <link href="../assets/_mkdocstrings.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Train";
        var mkdocs_page_input_path = "textile_classification\\train.md";
        var mkdocs_page_url = null;
      </script>
    
    <script src="../js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../index.html" class="icon icon-home"> Home
        </a>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../index.html">Home</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Textile Classification</span></p>
              <ul class="current">
                  <li class="toctree-l1 current"><a class="reference internal current" href="train.html">Train</a>
    <ul class="current">
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="test.html">Test</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="predict.html">Predict</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">Data_Setters</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="data_setters/create_csv_files.html">Create_CSV_Files</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="data_setters/data_set_creator.html">Data_Set_Creator</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">Models</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="models/pretrained_densenet.html">DenseNet</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="models/pretrained_efficientnet.html">EfficientNet</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="models/pretrained_resnext.html">ResNeXt</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">Utils</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="utils/data_set_visualization.html">Data_Set_Visualization</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="utils/metric_calculation_visualization.html">Metric_Calculation_Visualization</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="utils/miscellaneous.html">miscellaneous</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="utils/model_tracking.html">model_tracking</a>
                </li>
    </ul>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Home</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html" class="icon icon-home" alt="Docs"></a> &raquo;</li>
          <li>Textile Classification &raquo;</li>
      <li>Train</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/srahmatian/texture_classification/edit/master/docs/textile_classification/train.md" class="icon icon-github"> Edit on GitHub</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <div class="doc doc-object doc-module">


<a id="textile_classification.train"></a>
  <div class="doc doc-contents first">
  
      <p>Use this python file to train your model.
It reads the existed train.csv and validation.csv files to train the model
Note that you have to pass a .cfg file as the a argument when you want to run this file.
That .cfg file must contain required information for trainin the model.
Pleae take a look at train_input_info.cfg as a template.
You can create your own .cfg file with another name or just change the content of train_input_info.cfg</p>
<p>This is an example how you can train the model:</p>
<p>python .        extile_classification   rain.py .       extile_classification   rain_input_info.cfg</p>

  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h2 id="textile_classification.train.train_model" class="doc doc-heading">
<code class="highlight language-python"><span class="n">train_model</span><span class="p">(</span><span class="n">epochs_num</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">train_data_loader</span><span class="p">,</span> <span class="n">val_data_loader</span><span class="p">,</span> <span class="n">loss_function</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>This function is responsible for training the model. 
This function uses mlflow to log parameters, metrics, checkpoint, figures, and etc in the mlruns directory</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>epochs_num</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>determines the number of iterations on whole data set.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>model</code></td>
          <td>
                <code><span title="torch.nn">nn</span>.<span title="torch.nn.Module">Module</span></code>
          </td>
          <td><p>It also can has been loaded from a checkpoint</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>train_data_loader</code></td>
          <td>
                <code><span title="torch.utils.data.DataLoader">DataLoader</span></code>
          </td>
          <td><p>the data loader which is reposnbile for choosing batches from train's dataset</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>val_data_loader</code></td>
          <td>
                <code><span title="torch.utils.data.DataLoader">DataLoader</span></code>
          </td>
          <td><p>the data loader which is reposnbile for choosing batches from validation's dataset</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>loss_function</code></td>
          <td>
                <code>_type_</code>
          </td>
          <td><p>is responsible for calculating the gradients of model's parameter</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>optimizer</code></td>
          <td>
                <code>_type_</code>
          </td>
          <td><p>is responsbile for updating model's parameters based on their gradient</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>lr_scheduler</code></td>
          <td>
                <code>_type_</code>
          </td>
          <td><p>Is responsible for change learning rate</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>textile_classification\train.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">epochs_num</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
                <span class="n">train_data_loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">val_data_loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
                <span class="n">loss_function</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function is responsible for training the model. </span>
<span class="sd">    This function uses mlflow to log parameters, metrics, checkpoint, figures, and etc in the mlruns directory</span>

<span class="sd">    Args:</span>
<span class="sd">        epochs_num (int): determines the number of iterations on whole data set.</span>
<span class="sd">        model (nn.Module): It also can has been loaded from a checkpoint</span>
<span class="sd">        train_data_loader (DataLoader): the data loader which is reposnbile for choosing batches from train&#39;s dataset</span>
<span class="sd">        val_data_loader (DataLoader): the data loader which is reposnbile for choosing batches from validation&#39;s dataset</span>
<span class="sd">        loss_function (_type_): is responsible for calculating the gradients of model&#39;s parameter</span>
<span class="sd">        optimizer (_type_): is responsbile for updating model&#39;s parameters based on their gradient</span>
<span class="sd">        lr_scheduler (_type_, optional): Is responsible for change learning rate</span>
<span class="sd">    &quot;&quot;&quot;</span>


    <span class="n">ds_train_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_data_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">ds_val_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_data_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="c1"># we check validation loss to see if it gets better, </span>
    <span class="c1"># then we save it as a checkpoint</span>
    <span class="n">best_loss_val</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="k">for</span> <span class="n">epoch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs_num</span><span class="p">):</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch_idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="se">\n</span><span class="s2">-------------------------------&quot;</span><span class="p">)</span>

        <span class="c1"># Training Phase</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">losses_train_epoch</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">labels_grnd_truth_train_epoch</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">labels_predicted_train_epoch</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">image_pathes_train_epoch</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_data_loader</span><span class="p">):</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">images_batch</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">]</span>
            <span class="n">labels_grnd_truth_batch</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label_grnd_truth&quot;</span><span class="p">]</span>
            <span class="n">labels_predicted_batch</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images_batch</span><span class="p">)</span>
            <span class="c1"># the order of input argument for loss is very important</span>
            <span class="n">loss_batch</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">labels_predicted_batch</span><span class="p">,</span> <span class="n">labels_grnd_truth_batch</span><span class="p">)</span>
            <span class="n">loss_batch</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="c1"># convert a torch tensor having only one element to a ordinary python number.</span>
            <span class="n">loss_batch</span> <span class="o">=</span> <span class="n">loss_batch</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="c1"># print train loss every 25 batchs in info.log file</span>
            <span class="k">if</span> <span class="n">batch_idx</span> <span class="o">%</span> <span class="mi">25</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">ds_train_size_so_far</span> <span class="o">=</span> <span class="n">batch_idx</span> <span class="o">*</span> <span class="n">train_data_loader</span><span class="o">.</span><span class="n">batch_size</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;train_loss: </span><span class="si">{</span><span class="n">loss_batch</span><span class="si">:</span><span class="s2">0.5f</span><span class="si">}</span><span class="s2">, num_feeded_data/num_whole_data: [</span><span class="si">{</span><span class="n">ds_train_size_so_far</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">ds_train_size</span><span class="si">}</span><span class="s2">]&quot;</span>
                    <span class="p">)</span>

            <span class="c1"># we need to detach labels from gradient and send them on cpu, so numpy and scikit-learn could handle it.</span>
            <span class="c1"># since we are done with calculating loss, we don&#39;t need to worry about it.</span>
            <span class="c1"># we do the same thing for images in inside the log function since</span>
            <span class="c1"># we don&#39;t need to log images every batch or every epoch, so we don&#39;t increase required time</span>
            <span class="n">labels_grnd_truth_batch</span> <span class="o">=</span> <span class="n">labels_grnd_truth_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
            <span class="n">labels_predicted_batch</span> <span class="o">=</span> <span class="n">labels_predicted_batch</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
            <span class="n">log_after_feeding_each_batch</span><span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> 
                                         <span class="n">epoch_idx</span><span class="o">=</span><span class="n">epoch_idx</span><span class="p">,</span> 
                                         <span class="n">batch_idx</span><span class="o">=</span><span class="n">batch_idx</span><span class="p">,</span>
                                         <span class="n">data_set_size</span><span class="o">=</span><span class="n">ds_train_size</span><span class="p">,</span> 
                                         <span class="n">images</span><span class="o">=</span><span class="n">images_batch</span><span class="p">,</span>
                                         <span class="n">labels_grnd_truth</span><span class="o">=</span><span class="n">labels_grnd_truth_batch</span><span class="p">,</span>
                                         <span class="n">labels_predicted</span><span class="o">=</span><span class="n">labels_predicted_batch</span><span class="p">,</span>
                                         <span class="n">loss</span><span class="o">=</span><span class="n">loss_batch</span><span class="p">,</span> 
                                         <span class="n">epoch_frequency_image_log</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>                

            <span class="n">losses_train_epoch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_batch</span><span class="p">)</span>
            <span class="n">labels_grnd_truth_train_epoch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">labels_grnd_truth_batch</span><span class="p">)</span>
            <span class="n">labels_predicted_train_epoch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">labels_predicted_batch</span><span class="p">)</span>
            <span class="n">image_pathes_train_epoch</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">image_path</span> <span class="k">for</span> <span class="n">image_path</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;image_path&quot;</span><span class="p">]])</span>

        <span class="c1"># here is the end of (for batch_idx, batch in enumerate(train_data_loader))</span>

        <span class="n">log_after_ending_each_epoch</span><span class="p">(</span><span class="n">phase</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="n">epoch_idx</span><span class="o">=</span><span class="n">epoch_idx</span><span class="p">,</span> 
                                    <span class="n">labels_grnd_truth</span><span class="o">=</span><span class="n">labels_grnd_truth_train_epoch</span><span class="p">,</span>
                                    <span class="n">labels_predicted</span><span class="o">=</span><span class="n">labels_predicted_train_epoch</span><span class="p">,</span> 
                                    <span class="n">losses</span><span class="o">=</span><span class="n">losses_train_epoch</span><span class="p">)</span>

        <span class="c1"># Validation Phase</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">losses_val_epoch</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">labels_grnd_truth_val_epoch</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">labels_predicted_val_epoch</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">image_pathes_val_epoch</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">val_data_loader</span><span class="p">):</span>
                <span class="n">images_batch</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">]</span>
                <span class="n">labels_grnd_truth_batch</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;label_grnd_truth&quot;</span><span class="p">]</span>
                <span class="n">labels_predicted_batch</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images_batch</span><span class="p">)</span>
                <span class="c1"># the order of input argument for loss is very important</span>
                <span class="n">loss_batch</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">labels_predicted_batch</span><span class="p">,</span> <span class="n">labels_grnd_truth_batch</span><span class="p">)</span>
                <span class="c1"># convert a torch tensor having only one element to a ordinary python number.</span>
                <span class="n">loss_batch</span> <span class="o">=</span> <span class="n">loss_batch</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

                <span class="c1"># print validation loss every 25 batchs in info.log file</span>
                <span class="k">if</span> <span class="n">batch_idx</span> <span class="o">%</span> <span class="mi">25</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">ds_val_size_so_far</span> <span class="o">=</span> <span class="n">batch_idx</span> <span class="o">*</span> <span class="n">val_data_loader</span><span class="o">.</span><span class="n">batch_size</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;validation_loss: </span><span class="si">{</span><span class="n">loss_batch</span><span class="si">:</span><span class="s2">0.5f</span><span class="si">}</span><span class="s2">, num_feeded_data/num_whole_data: [</span><span class="si">{</span><span class="n">ds_val_size_so_far</span><span class="si">:</span><span class="s2">d</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">ds_val_size</span><span class="si">:</span><span class="s2">d</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>

                <span class="c1"># we need to send labels on cpu, so numpy and scikit-learn could handle it.</span>
                <span class="c1"># since we are done with calculating loss, we don&#39;t need to worry about it.</span>
                <span class="c1"># we do the same thing for images in inside the log function since</span>
                <span class="c1"># we don&#39;t need to log images every batch or every epoch, so we don&#39;t increase required time</span>
                <span class="n">labels_grnd_truth_batch</span> <span class="o">=</span> <span class="n">labels_grnd_truth_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
                <span class="n">labels_predicted_batch</span> <span class="o">=</span> <span class="n">labels_predicted_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
                <span class="n">log_after_feeding_each_batch</span><span class="p">(</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span> 
                                            <span class="n">epoch_idx</span><span class="o">=</span><span class="n">epoch_idx</span><span class="p">,</span> 
                                            <span class="n">batch_idx</span><span class="o">=</span><span class="n">batch_idx</span><span class="p">,</span>
                                            <span class="n">data_set_size</span><span class="o">=</span><span class="n">ds_val_size</span><span class="p">,</span> 
                                            <span class="n">images</span><span class="o">=</span><span class="n">images_batch</span><span class="p">,</span>
                                            <span class="n">labels_grnd_truth</span><span class="o">=</span><span class="n">labels_grnd_truth_batch</span><span class="p">,</span>
                                            <span class="n">labels_predicted</span><span class="o">=</span><span class="n">labels_predicted_batch</span><span class="p">,</span>
                                            <span class="n">loss</span><span class="o">=</span><span class="n">loss_batch</span><span class="p">,</span> 
                                            <span class="n">epoch_frequency_image_log</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>

                <span class="n">losses_val_epoch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_batch</span><span class="p">)</span>
                <span class="n">labels_grnd_truth_val_epoch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">labels_grnd_truth_batch</span><span class="p">)</span>
                <span class="n">labels_predicted_val_epoch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">labels_predicted_batch</span><span class="p">)</span>
                <span class="n">image_pathes_val_epoch</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">image_path</span> <span class="k">for</span> <span class="n">image_path</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;image_path&quot;</span><span class="p">]])</span>

            <span class="c1"># here is the end of (for batch_idx, batch in enumerate(val_data_loader))</span>
        <span class="c1"># here is the end of (with torch.no_grad())</span>

        <span class="n">log_after_ending_each_epoch</span><span class="p">(</span><span class="n">phase</span><span class="o">=</span> <span class="s2">&quot;validation&quot;</span><span class="p">,</span> <span class="n">epoch_idx</span><span class="o">=</span><span class="n">epoch_idx</span><span class="p">,</span> 
                                    <span class="n">labels_grnd_truth</span><span class="o">=</span><span class="n">labels_grnd_truth_val_epoch</span><span class="p">,</span>
                                    <span class="n">labels_predicted</span><span class="o">=</span><span class="n">labels_predicted_val_epoch</span><span class="p">,</span> 
                                    <span class="n">losses</span><span class="o">=</span><span class="n">losses_val_epoch</span><span class="p">)</span>

        <span class="c1"># Record and Update Learning Rate</span>
        <span class="k">if</span> <span class="n">lr_scheduler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">lr_scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">current_lr</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span>
            <span class="c1"># log learing rate</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;train/per_epoch/learning_rate&quot;</span><span class="p">,</span> <span class="n">current_lr</span><span class="p">,</span> <span class="n">epoch_idx</span><span class="p">)</span>

        <span class="c1"># check the validation loss evey 50 ephoc to see if the model perform better or not,</span>
        <span class="c1"># if it is better than previous check, we will save it a checkpoint.</span>
        <span class="k">if</span> <span class="n">epoch_idx</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">loss_val_mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">losses_val_epoch</span><span class="p">))</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">loss_val_mean</span> <span class="o">&lt;</span> <span class="n">best_loss_val</span><span class="p">:</span>
                <span class="n">best_loss_val</span> <span class="o">=</span> <span class="n">loss_val_mean</span>

                <span class="n">loss_train_mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">losses_train_epoch</span><span class="p">))</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

                <span class="c1"># save the best checkpoint to continue training later if it was necessay.</span>
                <span class="c1"># also for using it in test and prediction phase</span>
                <span class="c1"># we almost save everthing to be able of retrieving the condistion of the last checkpoint</span>
                <span class="c1"># we also need to need to save ds_train to use the same transformation for testing</span>
                <span class="n">checkpoint</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="n">loss_train_mean</span><span class="p">,</span>
                    <span class="s2">&quot;model_state_dict&quot;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                    <span class="s2">&quot;optimizer_state_dict&quot;</span><span class="p">:</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                    <span class="s2">&quot;lr_scheduler_state_dict&quot;</span><span class="p">:</span> <span class="n">lr_scheduler</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                    <span class="s2">&quot;data_set&quot;</span><span class="p">:</span> <span class="n">ds_train</span><span class="p">,</span>
                    <span class="s2">&quot;loss_function&quot;</span><span class="p">:</span> <span class="n">loss_function</span><span class="p">,</span>
                    <span class="s2">&quot;model_type&quot;</span><span class="p">:</span> <span class="nb">type</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">}</span>

                <span class="n">checkpoint_path</span> <span class="o">=</span> <span class="n">BASE_DIR</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="s2">&quot;checkpoint.pt&quot;</span><span class="p">)</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">checkpoint_path</span><span class="p">)</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_artifact</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">,</span> <span class="s2">&quot;saved_checkpoints/best_checkpoint&quot;</span><span class="p">)</span>
                <span class="c1"># after loggin the checlpoint in mlrun, </span>
                <span class="c1"># we remove its source to avoid keeping same files at different loation</span>
                <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">)</span>

                <span class="n">log_overal_performance_afer_ending_all_epoch</span><span class="p">(</span>
                    <span class="n">phase</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> 
                    <span class="n">labels_grnd_truth</span><span class="o">=</span><span class="n">labels_grnd_truth_train_epoch</span><span class="p">,</span>
                    <span class="n">labels_predicted</span><span class="o">=</span><span class="n">labels_predicted_train_epoch</span><span class="p">,</span>
                    <span class="n">losses</span><span class="o">=</span><span class="n">losses_train_epoch</span><span class="p">)</span>

                <span class="n">log_overal_performance_afer_ending_all_epoch</span><span class="p">(</span>
                    <span class="n">phase</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span> 
                    <span class="n">labels_grnd_truth</span><span class="o">=</span><span class="n">labels_grnd_truth_val_epoch</span><span class="p">,</span>
                    <span class="n">labels_predicted</span><span class="o">=</span><span class="n">labels_predicted_val_epoch</span><span class="p">,</span>
                    <span class="n">losses</span><span class="o">=</span><span class="n">losses_val_epoch</span><span class="p">)</span>

                <span class="c1"># create csv files for the best checkpoint to see </span>
                <span class="c1"># which images is classified correctly and which one is not.</span>
                <span class="k">for</span> <span class="n">csv_name</span><span class="p">,</span> <span class="n">image_pathes</span><span class="p">,</span> <span class="n">labels_grnd_truth</span><span class="p">,</span> <span class="n">labels_predicted</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                    <span class="p">[</span><span class="s2">&quot;train.csv&quot;</span><span class="p">,</span> <span class="s2">&quot;validation.csv&quot;</span><span class="p">],</span>
                    <span class="p">[</span><span class="n">image_pathes_train_epoch</span><span class="p">,</span> <span class="n">image_pathes_val_epoch</span><span class="p">],</span> 
                    <span class="p">[</span><span class="n">labels_grnd_truth_train_epoch</span><span class="p">,</span> <span class="n">labels_grnd_truth_val_epoch</span><span class="p">],</span>
                    <span class="p">[</span><span class="n">labels_predicted_train_epoch</span><span class="p">,</span> <span class="n">labels_predicted_val_epoch</span><span class="p">]):</span>

                        <span class="n">labels_grnd_truth</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">labels_grnd_truth</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                        <span class="n">labels_predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">labels_predicted</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

                        <span class="n">labels_grnd_truth</span> <span class="o">=</span> <span class="n">change_labels_from_one_hot_fromat_to_binary_format</span><span class="p">(</span>
                            <span class="n">labels_grnd_truth</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
                        <span class="n">labels_predicted</span> <span class="o">=</span> <span class="n">change_labels_from_one_hot_fromat_to_binary_format</span><span class="p">(</span>
                            <span class="n">labels_predicted</span><span class="p">)</span>

                        <span class="n">labels_predicted</span> <span class="o">=</span> <span class="n">change_labels_from_probablity_format_to_deterministic_format</span><span class="p">(</span>
                            <span class="n">labels_predicted</span><span class="p">,</span> 
                            <span class="n">is_one_hot_format</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

                        <span class="n">create_csv_files_containing_both_true_and_predicted_labels</span><span class="p">(</span>
                            <span class="n">csv_name</span><span class="o">=</span><span class="n">csv_name</span><span class="p">,</span>
                            <span class="n">image_pathes</span><span class="o">=</span><span class="n">image_pathes</span><span class="p">,</span>
                            <span class="n">labels_grund_truth</span><span class="o">=</span><span class="n">labels_grnd_truth</span><span class="p">,</span> 
                            <span class="n">labels_predicted</span><span class="o">=</span><span class="n">labels_predicted</span><span class="p">,</span>
                            <span class="n">csv_dir</span><span class="o">=</span><span class="n">BASE_DIR</span><span class="p">)</span>

                        <span class="n">csv_path</span> <span class="o">=</span> <span class="n">BASE_DIR</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">csv_name</span><span class="p">)</span>
                        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_artifact</span><span class="p">(</span><span class="n">csv_path</span><span class="p">,</span> <span class="s2">&quot;csv_files&quot;</span><span class="p">)</span>
                        <span class="c1"># after loggin the csv file in mlrun, </span>
                        <span class="c1"># we remove its source to avoid keeping same files at different loation</span>
                        <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">csv_path</span><span class="p">)</span>
            <span class="c1"># end of (if loss_val_mean &lt; best_loss_val:)</span>

    <span class="c1"># here is the end of (epoch_idx in range(epochs_num))</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Training is Done&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>



  </div>

  </div>

</div>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../index.html" class="btn btn-neutral float-left" title="Home"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="test.html" class="btn btn-neutral float-right" title="Test">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/srahmatian/texture_classification" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
      <span><a href="../index.html" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="test.html" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme_extra.js" defer></script>
    <script src="../js/theme.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
